<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="icon" href="../../Peano-icon.png" type="image/x-icon" />
<title>Peano</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-tabs.js"></script>
<script type="text/javascript" src="../../toggle-alternative-theme.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
    DoxygenAwesomeTabs.init()
</script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../custom.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
<link href="../../custom-alternative.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<!-- https://bryce.io/gitlab-corners/ -->
<style>.gitlab-corner-wrapper{overflow:hidden;width:100px;height:100px;position:absolute;top:0;right:0}.gitlab-corner{position:absolute;top:-16px;right:-50px;transform:rotate(45deg);background:#333;border:44px solid #333;border-bottom:none;border-top:#333 solid 16px}.gitlab-corner svg{width:60px;height:60px;margin-bottom:-4px}.cls-1{fill:#fc6d26}.cls-2{fill:#e24329}.cls-3{fill:#fca326}.gitlab-corner:hover .cls-1{animation:cycle .6s}.gitlab-corner:hover .cls-2{animation:cycleMid .6s}.gitlab-corner:hover .cls-3{animation:cycleEnd .6s}@keyframes cycle{100%,15%,60%{fill:#fc6d26}30%,75%{fill:#e24329}45%,90%{fill:#fca326}}@keyframes cycleMid{100%,15%,60%{fill:#e24329}30%,75%{fill:#fca326}45%,90%{fill:#fc6d26}}@keyframes cycleEnd{100%,15%,60%{fill:#fca326}30%,75%{fill:#fc6d26}45%,90%{fill:#e24329}}@media (max-width:500px){.gitlab-corner:hover .cls-1,.gitlab-corner:hover .cls-2,.gitlab-corner:hover .cls-3{animation:none}.gitlab-corner .cls-1{animation:cycle .6s}.gitlab-corner .cls-2{animation:cycleMid .6s}.gitlab-corner .cls-3{animation:cycleEnd .6s}}</style><div class="gitlab-corner-wrapper"><a href="https://gitlab.lrz.de/hpcsoftware/Peano" class="gitlab-corner" aria-label="View source on GitLab"><svg id="logo_art" data-name="logo art" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 586 559"><g id="g44"><path id="path46" class="cls-1" d="M461.17,301.83l-18.91-58.12L404.84,128.43a6.47,6.47,0,0,0-12.27,0L355.15,243.64H230.82L193.4,128.43a6.46,6.46,0,0,0-12.26,0L143.78,243.64l-18.91,58.19a12.88,12.88,0,0,0,4.66,14.39L293,435,456.44,316.22a12.9,12.9,0,0,0,4.73-14.39"/></g><g id="g48"><path id="path50" class="cls-2" d="M293,434.91h0l62.16-191.28H230.87L293,434.91Z"/></g><g id="g56"><path id="path58" class="cls-1" d="M293,434.91,230.82,243.63h-87L293,434.91Z"/></g><g id="g64"><path id="path66" class="cls-3" d="M143.75,243.69h0l-18.91,58.12a12.88,12.88,0,0,0,4.66,14.39L293,435,143.75,243.69Z"/></g><g id="g72"><path id="path74" class="cls-2" d="M143.78,243.69h87.11L193.4,128.49a6.47,6.47,0,0,0-12.27,0l-37.35,115.2Z"/></g><g id="g76"><path id="path78" class="cls-1" d="M293,434.91l62.16-191.28H442.3L293,434.91Z"/></g><g id="g80"><path id="path82" class="cls-3" d="M442.24,243.69h0l18.91,58.12a12.85,12.85,0,0,1-4.66,14.39L293,434.91l149.2-191.22Z"/></g><g id="g84"><path id="path86" class="cls-2" d="M442.28,243.69h-87.1l37.42-115.2a6.46,6.46,0,0,1,12.26,0l37.42,115.2Z"/></g></svg></a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../Peano-icon.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Peano
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('d7/d0f/benchmarks_exahype2_ccz4_single_black_hole.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Solver coupling (Single Schwarzschild black hole)</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#autotoc_md686">Build executable</a></li>
<li class="level1"><a href="#autotoc_md687">Clean up old and temporary files</a></li>
<li class="level1"><a href="#autotoc_md688">Visualise outcome</a></li>
<li class="level1"><a href="#autotoc_md689">Benchmark runs</a><ul><li class="level2"><a href="#autotoc_md690">Single node performance data studying task orchestration and kernel variants</a><ul><li class="level3"><a href="#autotoc_md691">No AMR</a></li>
<li class="level3"><a href="#autotoc_md692">With adaptive mesh refinement</a></li>
<li class="level3"><a href="#autotoc_md693">Script to create these data</a></li>
</ul>
</li>
<li class="level2"><a href="#autotoc_md694">Upscaling studies</a><ul><li class="level3"><a href="#autotoc_md695">SLURM scripts</a></li>
<li class="level3"><a href="#autotoc_md696">Data gathering</a></li>
<li class="level3"><a href="#autotoc_md697">Visualisation</a></li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md698">Production runs</a></li>
<li class="level1"><a href="#autotoc_md699">Code remarks (FD4-FV scheme)</a><ul><li class="level2"><a href="#autotoc_md700">Time step size</a></li>
<li class="level2"><a href="#autotoc_md701">The Finite Volume solver</a></li>
<li class="level2"><a href="#autotoc_md702">The FD4 solver</a><ul><li class="level3"><a href="#autotoc_md703">FD4-FV coupling (projection)</a></li>
<li class="level3"><a href="#autotoc_md704">FV-FD4 coupling (restriction)</a></li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md705">Optimisation</a><ul><li class="level2"><a href="#autotoc_md706">Domain decomposition</a></li>
<li class="level2"><a href="#autotoc_md707">High level code tuning</a></li>
<li class="level2"><a href="#autotoc_md708">Concurrency analysis with default task orchestration</a></li>
<li class="level2"><a href="#autotoc_md709">Optimise the actual compute kernels</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p>Benchmark which solves the single black hole described in a ExaGRyPE simulation. While the output is not particularly exciting (the simulation should yield a stationary solution after a while), it is numerically challenging as we have sophisticated boundary condition effects, a singularity in the centre which can lead to oscillations, need a scheme with low numerical dissipation, and so forth. Therefore, this benchmark combines two different solvers - a dissipative Finite Volume scheme and a higher order scheme - to obtain a compromise between accuracy and stability.</p>
<div style="background-color: #ccf ; padding: 10px; border: 1px solid green;"> For this benchmark, the following extensions are mandatory:</div><div style="background-color: #ccf ; padding: 10px; border: 1px solid green;"><ul>
<li>blockstructured (<code>--enable-blockstructured</code>)</li>
<li><a class="el" href="../../dd/d6c/namespaceexahype2.html" title="For the generic kernels that I use here most of the time.">exahype2</a> (<code>--enable-exahype2</code>)</li>
</ul>
</div><div style="background-color: #ccf ; padding: 10px; border: 1px solid green;"> Furthermore, you will need the GNU Scientific Library (GSL) installed on your system. </div><h1><a class="anchor" id="autotoc_md686"></a>
Build executable</h1>
<div class="fragment"><div class="line"><span class="keyword">export</span> PYTHONPATH=../../../../python:../../../../<a class="code hl_namespace" href="../../db/d75/namespaceapplications.html">applications</a>/<a class="code hl_namespace" href="../../dd/d6c/namespaceexahype2.html">exahype2</a>/<a class="code hl_namespace" href="../../dc/db2/namespaceccz4.html">ccz4</a></div>
<div class="line"> </div>
<div class="line">python3 performance-studies.py -lbm tailored -s fd4-rk1-limited-ps-3 --scheduler native-no-priorities --trees 6</div>
<div class="ttc" id="anamespaceapplications_html"><div class="ttname"><a href="../../db/d75/namespaceapplications.html">applications</a></div><div class="ttdoc">This code is taken from the original ExaHyPE project written by colleagues from the University of Tre...</div><div class="ttdef"><b>Definition</b> <a href="../../d9/d06/benchmarks_2exahype2_2ccz4_2performance-testbed_2CCZ4Kernels_8h_source.html#l00014">CCZ4Kernels.h:14</a></div></div>
<div class="ttc" id="anamespaceccz4_html"><div class="ttname"><a href="../../dc/db2/namespaceccz4.html">ccz4</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db6/ccz4_8py_source.html#l00001">ccz4.py:1</a></div></div>
<div class="ttc" id="anamespaceexahype2_html"><div class="ttname"><a href="../../dd/d6c/namespaceexahype2.html">exahype2</a></div><div class="ttdoc">For the generic kernels that I use here most of the time.</div><div class="ttdef"><b>Definition</b> <a href="../../d0/d65/CellAccess_8h_source.html#l00013">CellAccess.h:13</a></div></div>
</div><!-- fragment --><p>As always, the parameter &ndash;help makes the Python script yield further info, while the sections below enlist characteristic choices of the parameters. There are different scripts in the directory. They serve different purposes and support slightly different parameters.</p>
<p>Depending on your system, you might have to load the GSL module separately before you build the application:</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> load gsl</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md687"></a>
Clean up old and temporary files</h1>
<p>The following statements remove all the glue code and autogenerated C++ files. There is no risk in deleting them - if you rerun the Python script, they will all be reinstantiated.</p>
<div class="fragment"><div class="line">rm *.o *.cmake</div>
<div class="line">rm README-*.md</div>
<div class="line">rm Makefile CMakeLists.txt</div>
<div class="line">rm Abstract*</div>
<div class="line">rm -rf celldata facedata globaldata observers tasks vertexdata repositories</div>
</div><!-- fragment --><p>To get rid of the output files, type in</p>
<div class="fragment"><div class="line">rm *patch-file *vtu *.pvd *.bak *.csv</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md688"></a>
Visualise outcome</h1>
<p>If you have set up your experiment via the Python script with the -plot command, you can use the standard Peano scripts to convert <a class="el" href="../../df/d47/documentation_tarch_visualisation.html">Peano's patch files</a>:</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PYTHONPATH=../../../../python</div>
<div class="line">/opt/paraview/bin/pvpython ~/git/Peano/python/<a class="code hl_namespace" href="../../d8/d8f/namespacepeano4.html">peano4</a>/visualisation/render.py --filter-fine-grid solution-CCZ4SBH_FV.peano-patch-file</div>
<div class="line">/opt/paraview/bin/pvpython ~/git/Peano/python/<a class="code hl_namespace" href="../../d8/d8f/namespacepeano4.html">peano4</a>/visualisation/render.py --filter-fine-grid solution-CCZ4SBH_FD4.peano-patch-file</div>
<div class="ttc" id="anamespacepeano4_html"><div class="ttname"><a href="../../d8/d8f/namespacepeano4.html">peano4</a></div><div class="ttdef"><b>Definition</b> <a href="../../df/d17/CellMarker_8h_source.html#l00014">CellMarker.h:14</a></div></div>
</div><!-- fragment --><p>The picture below is taken from <a class="el" href="../../da/d8c/tutorials_exahype2_coupling.html">ExaHyPE's coupling discussion</a> and illustrates that the higher order solver covers the whole domain, while the FV is only active in a tiny cross-shaped region within.</p>
<div class="image">
<img src="../../grid-setup.png" alt=""/>
</div>
<h1><a class="anchor" id="autotoc_md689"></a>
Benchmark runs</h1>
<p>Benchmarking the single black hole is not easy, as it is a rather complex setup already with a rather long initialisation and grid construction phase. However, it is possible to benchmark it once you disable plots, the tracers, and you use an unreasonable coarse mesh.</p>
<p>For all the upscaling studies, we use the same kind of benchmarks. They can be generated in one go through</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PREFIX=<a class="code hl_namespace" href="../../df/d30/namespacetbb.html">tbb</a> or omp or sycl</div>
<div class="line"> </div>
<div class="line">rm $PREFIX-*</div>
<div class="line"> </div>
<div class="line">function compile() {</div>
<div class="line">  <span class="keywordflow">for</span> SCHEDULER in native-no-priorities native tailored <a class="code hl_namespace" href="../../d1/d80/namespaceparallel.html">parallel</a>-<span class="keywordflow">for</span> subtasks subtasks-and-kernel-parallelisation</div>
<div class="line">  <span class="keywordflow">do</span></div>
<div class="line">    <span class="keywordflow">for</span> TREES in 1 6 8 12</div>
<div class="line">    <span class="keywordflow">do</span></div>
<div class="line">      OUTPUT=$PREFIX-without-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">      python3 performance-studies.py  -lbm tailored -s fd4-rk1-limited-ps-6 --cell-size $CELL_SIZE --scheduler $SCHEDULER --trees $TREES -et $END_TIME --output $OUTPUT</div>
<div class="line">     </div>
<div class="line">      OUTPUT=$PREFIX-with-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">      python3 performance-studies.py  -lbm tailored -s fd4-rk1-limited-ps-6 --cell-size $CELL_SIZE --amr --scheduler $SCHEDULER --trees $TREES -et $END_TIME --output $OUTPUT</div>
<div class="line">    done</div>
<div class="line">  done</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keyword">export</span> CELL_SIZE=1.8</div>
<div class="line"><span class="keyword">export</span> END_TIME=1e-2</div>
<div class="line">compile</div>
<div class="line"><span class="keyword">export</span> CELL_SIZE=0.6</div>
<div class="line"><span class="keyword">export</span> END_TIME=1e-3</div>
<div class="line">compile</div>
<div class="line"><span class="keyword">export</span> CELL_SIZE=0.1</div>
<div class="line"><span class="keyword">export</span> END_TIME=1e-4</div>
<div class="line">compile</div>
<div class="ttc" id="anamespaceparallel_html"><div class="ttname"><a href="../../d1/d80/namespaceparallel.html">parallel</a></div><div class="ttdoc">The parallel namespace is Peano's core abstracts from both MPI and multicore parallelisation.</div></div>
<div class="ttc" id="anamespacetbb_html"><div class="ttname"><a href="../../df/d30/namespacetbb.html">tbb</a></div><div class="ttdoc">I've written an API to IIT, but I'm not currently using.</div><div class="ttdef"><b>Definition</b> <a href="../../df/d8b/blocked__rangeNd_8h_source.html#l00032">blocked_rangeNd.h:32</a></div></div>
</div><!-- fragment --><p>I have played around with a lot of different parameter settings. Some insights are summarised below for a normal setup as we find it on Hamilton:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Description   </th><th class="markdownTableHeadNone">Cell size   </th><th class="markdownTableHeadNone">End time   </th><th class="markdownTableHeadNone">Patch size   </th><th class="markdownTableHeadNone">Remarks    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Minimal setup   </td><td class="markdownTableBodyNone">1.8   </td><td class="markdownTableBodyNone">1e-2   </td><td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">You cannot see AMR here, and the FV patch size means that the CFD conditions do not match. This is a toy setup for a local laptop. It scales only up to 4-8 cores, as it so too small. Despite the small patch size (6 is production-mode level), we see the impact of the lack of scaling.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Proper minimal setup   </td><td class="markdownTableBodyNone">1.8   </td><td class="markdownTableBodyNone">1e-2   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">You cannot see AMR here either, but the FV patch size is a proper one, i.e. the black hole is resolved such that the CFL conditions of the FV and FD scheme match.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">One node setup   </td><td class="markdownTableBodyNone">0.6   </td><td class="markdownTableBodyNone">1e-3   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">This setup is already too big to be solved without AMR on a single node. We see that normal, native tasking performs best.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">One node setpu   </td><td class="markdownTableBodyNone">0.1   </td><td class="markdownTableBodyNone">1e-4   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">Use xxx nodes for regular grid   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md690"></a>
Single node performance data studying task orchestration and kernel variants</h2>
<p>Below are some performance data which I collected on my local workstation. They provide a first look-n-feel of what the code behaves. Please note that these results are definitely not representative, as they are acquired on an eight core machine. Modern workstations feature more cores and hence provide qualitatively different outcomes.</p>
<h3><a class="anchor" id="autotoc_md691"></a>
No AMR</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Name   </th><th class="markdownTableHeadRight">Trees   </th><th class="markdownTableHeadLeft">Scheduler   </th><th class="markdownTableHeadLeft">Python script call   </th><th class="markdownTableHeadRight">TBB   </th><th class="markdownTableHeadRight">OpenMP   </th><th class="markdownTableHeadRight">SYCL    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">(Almost) No parallel task producers   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native-no-priorities &ndash;trees 1   </td><td class="markdownTableBodyRight">527   </td><td class="markdownTableBodyRight">532   </td><td class="markdownTableBodyRight">560    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native &ndash;trees 1   </td><td class="markdownTableBodyRight">518   </td><td class="markdownTableBodyRight">529   </td><td class="markdownTableBodyRight">566    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler tailored &ndash;trees 1   </td><td class="markdownTableBodyRight">516   </td><td class="markdownTableBodyRight">534   </td><td class="markdownTableBodyRight">562    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler parallel-for &ndash;trees 1   </td><td class="markdownTableBodyRight">307   </td><td class="markdownTableBodyRight">637   </td><td class="markdownTableBodyRight">560    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler subtasks &ndash;trees 1   </td><td class="markdownTableBodyRight">302   </td><td class="markdownTableBodyRight">534   </td><td class="markdownTableBodyRight">565    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Fewer BSP sections than threads   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native-no-priorities &ndash;trees 6   </td><td class="markdownTableBodyRight">428   </td><td class="markdownTableBodyRight">457   </td><td class="markdownTableBodyRight">698    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native &ndash;trees 6   </td><td class="markdownTableBodyRight">430   </td><td class="markdownTableBodyRight">456   </td><td class="markdownTableBodyRight">597    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler tailored &ndash;trees 6   </td><td class="markdownTableBodyRight">427   </td><td class="markdownTableBodyRight">453   </td><td class="markdownTableBodyRight">605    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler parallel-for &ndash;trees 6   </td><td class="markdownTableBodyRight">225   </td><td class="markdownTableBodyRight">454   </td><td class="markdownTableBodyRight">600    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler subtasks &ndash;trees 6   </td><td class="markdownTableBodyRight">223   </td><td class="markdownTableBodyRight">453   </td><td class="markdownTableBodyRight">605    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">One BSP section per threads   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native-no-priorities &ndash;trees 8   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">436   </td><td class="markdownTableBodyRight">610    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native &ndash;trees 8   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">433   </td><td class="markdownTableBodyRight">611    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler tailored &ndash;trees 8   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">434   </td><td class="markdownTableBodyRight">617    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler parallel-for &ndash;trees 8   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">615    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler subtasks &ndash;trees 8   </td><td class="markdownTableBodyRight">207   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">618    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Threads overbooked with BSP sections   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native-no-priorities &ndash;trees 12   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">432   </td><td class="markdownTableBodyRight">606    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler native &ndash;trees 12   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">435   </td><td class="markdownTableBodyRight">607    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler tailored &ndash;trees 12   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">432   </td><td class="markdownTableBodyRight">618    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler parallel-for &ndash;trees 12   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyRight">435   </td><td class="markdownTableBodyRight">611    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 &ndash;scheduler subtasks &ndash;trees 12   </td><td class="markdownTableBodyRight">212   </td><td class="markdownTableBodyRight">482   </td><td class="markdownTableBodyRight">616   </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md692"></a>
With adaptive mesh refinement</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Name   </th><th class="markdownTableHeadRight">Trees   </th><th class="markdownTableHeadLeft">Scheduler   </th><th class="markdownTableHeadLeft">Python script call   </th><th class="markdownTableHeadRight">TBB   </th><th class="markdownTableHeadRight">OpenMP   </th><th class="markdownTableHeadRight">SYCL    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">(Almost) No parallel task producers   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native-no-priorities &ndash;trees 1   </td><td class="markdownTableBodyRight">408   </td><td class="markdownTableBodyRight">435   </td><td class="markdownTableBodyRight">343    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native &ndash;trees 1   </td><td class="markdownTableBodyRight">406   </td><td class="markdownTableBodyRight">433   </td><td class="markdownTableBodyRight">340    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler tailored &ndash;trees 1   </td><td class="markdownTableBodyRight">415   </td><td class="markdownTableBodyRight">434   </td><td class="markdownTableBodyRight">341    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler parallel-for &ndash;trees 1   </td><td class="markdownTableBodyRight">194   </td><td class="markdownTableBodyRight">432   </td><td class="markdownTableBodyRight">341    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">x   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler subtasks &ndash;trees 1   </td><td class="markdownTableBodyRight">193   </td><td class="markdownTableBodyRight">434   </td><td class="markdownTableBodyRight">341    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Fewer BSP sections than threads   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native-no-priorities &ndash;trees 6   </td><td class="markdownTableBodyRight">398   </td><td class="markdownTableBodyRight">420   </td><td class="markdownTableBodyRight">365    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native &ndash;trees 6   </td><td class="markdownTableBodyRight">396   </td><td class="markdownTableBodyRight">419   </td><td class="markdownTableBodyRight">363    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler tailored &ndash;trees 6   </td><td class="markdownTableBodyRight">398   </td><td class="markdownTableBodyRight">418   </td><td class="markdownTableBodyRight">359    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler parallel-for &ndash;trees 6   </td><td class="markdownTableBodyRight">186   </td><td class="markdownTableBodyRight">419   </td><td class="markdownTableBodyRight">357    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">6   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler subtasks &ndash;trees 6   </td><td class="markdownTableBodyRight">183   </td><td class="markdownTableBodyRight">420   </td><td class="markdownTableBodyRight">361    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">One BSP section per threads   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native-no-priorities &ndash;trees 8   </td><td class="markdownTableBodyRight">390   </td><td class="markdownTableBodyRight">413   </td><td class="markdownTableBodyRight">374    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native &ndash;trees 8   </td><td class="markdownTableBodyRight">386   </td><td class="markdownTableBodyRight">414   </td><td class="markdownTableBodyRight">364    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler tailored &ndash;trees 8   </td><td class="markdownTableBodyRight">390   </td><td class="markdownTableBodyRight">413   </td><td class="markdownTableBodyRight">373    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler parallel-for &ndash;trees 8   </td><td class="markdownTableBodyRight">178   </td><td class="markdownTableBodyRight">412   </td><td class="markdownTableBodyRight">374    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">8   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler subtasks &ndash;trees 8   </td><td class="markdownTableBodyRight">181   </td><td class="markdownTableBodyRight">414   </td><td class="markdownTableBodyRight">375    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Threads overbooked with BSP sections   </td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td><td class="markdownTableBodyRight"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Native tasking w/o priorities   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">native-no-priorities   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native-no-priorities &ndash;trees 12   </td><td class="markdownTableBodyRight">391   </td><td class="markdownTableBodyRight">415   </td><td class="markdownTableBodyRight">375    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Native tasking with priorities   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">native   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler native &ndash;trees 12   </td><td class="markdownTableBodyRight">392   </td><td class="markdownTableBodyRight">413   </td><td class="markdownTableBodyRight">365    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Tailored task scheduling   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">tailored   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler tailored &ndash;trees 12   </td><td class="markdownTableBodyRight">390   </td><td class="markdownTableBodyRight">446   </td><td class="markdownTableBodyRight">366    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Parallel for   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">parallel-for   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler parallel-for &ndash;trees 12   </td><td class="markdownTableBodyRight">182   </td><td class="markdownTableBodyRight">412   </td><td class="markdownTableBodyRight">375    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Subtasks   </td><td class="markdownTableBodyRight">12   </td><td class="markdownTableBodyLeft">subtasks   </td><td class="markdownTableBodyLeft">python3 <a class="el" href="../../d5/db3/performance-studies_8py.html">performance-studies.py</a> -lbm tailored -s fd4-rk1-limited-ps-3 -amr &ndash;scheduler subtasks &ndash;trees 12   </td><td class="markdownTableBodyRight">178   </td><td class="markdownTableBodyRight">506   </td><td class="markdownTableBodyRight">377   </td></tr>
</table>
<p>The above measurements are done on my eight core laptop with the Intel oneAPI toolchain.</p>
<h3><a class="anchor" id="autotoc_md693"></a>
Script to create these data</h3>
<p>Below is a script that creates all data points in one go. You will have to amend the prefix accordingly.</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PREFIX=<a class="code hl_namespace" href="../../df/d30/namespacetbb.html">tbb</a> or omp or sycl</div>
<div class="line"> </div>
<div class="line"><span class="keyword">export</span> CELL_SIZE=1.8</div>
<div class="line"><span class="keyword">export</span> RESULTS_FOLDER=results-single-node-orchestration-<a class="code hl_namespace" href="../../d3/d22/namespacebenchmarks.html">benchmarks</a></div>
<div class="line">mkdir $RESULTS_FOLDER</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">for</span> SCHEDULER in native-no-priorities native tailored <a class="code hl_namespace" href="../../d1/d80/namespaceparallel.html">parallel</a>-<span class="keywordflow">for</span> subtasks subtasks-and-kernel-parallelisation</div>
<div class="line"><span class="keywordflow">do</span></div>
<div class="line">  <span class="keywordflow">for</span> TREES in 1 6 8 12</div>
<div class="line">  <span class="keywordflow">do</span></div>
<div class="line">    OUTPUT=$PREFIX-without-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt</div>
<div class="line">    </div>
<div class="line">    OUTPUT=$PREFIX-with-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt  </div>
<div class="line">  done</div>
<div class="line">done</div>
<div class="ttc" id="anamespacebenchmarks_html"><div class="ttname"><a href="../../d3/d22/namespacebenchmarks.html">benchmarks</a></div><div class="ttdef"><b>Definition</b> <a href="../../d5/d80/Poisson_8h_source.html#l00015">Poisson.h:15</a></div></div>
</div><!-- fragment --><p>If you create the files as per the script above, you can extract the quantities of interest as follows:</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PREFIX=<a class="code hl_namespace" href="../../df/d30/namespacetbb.html">tbb</a> or omp or sycl</div>
<div class="line"> </div>
<div class="line"><span class="keyword">export</span> CELL_SIZE=1.8</div>
<div class="line"> </div>
<div class="line">OUTPUT=results/$PREFIX.txt</div>
<div class="line">echo $PREFIX &gt; $OUTPUT</div>
<div class="line"><span class="keywordflow">for</span> AMR in without-amr with-amr</div>
<div class="line"><span class="keywordflow">do</span></div>
<div class="line">  <span class="keywordflow">for</span> TREES in 1 6 8 12</div>
<div class="line">  <span class="keywordflow">do</span></div>
<div class="line">    <span class="keywordflow">for</span> SCHEDULER in native-no-priorities native tailored <a class="code hl_namespace" href="../../d1/d80/namespaceparallel.html">parallel</a>-<span class="keywordflow">for</span> subtasks subtasks-and-kernel-parallelisation</div>
<div class="line">    <span class="keywordflow">do</span></div>
<div class="line">      FILE=results/$PREFIX-$AMR-$SCHEDULER-$TREES-trees-$CELL_SIZE.txt</div>
<div class="line">      echo $FILE &gt;&gt; $OUTPUT</div>
<div class="line">      grep <span class="stringliteral">&quot;time stepping:&quot;</span> $FILE &gt;&gt; $OUTPUT</div>
<div class="line">    done</div>
<div class="line">  done</div>
<div class="line">done</div>
<div class="line">echo wrote all data to $OUTPUT</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md694"></a>
Upscaling studies</h2>
<p>The upscaling studies yield graphs as the ones below, which highlight various characteristics of the code base:</p>
<div class="image">
<img src="../../omp-8-trees-with-amr-cs-1.8-ps-3.png" alt=""/>
</div>
 <div class="image">
<img src="../../omp-8-trees-with-amr-cs-0.6-ps-6.png" alt=""/>
</div>
<h3><a class="anchor" id="autotoc_md695"></a>
SLURM scripts</h3>
<p>The upscaling studies are triggered by the script below, which you might want to embed into a Slurm script to really acquire the data quickly. This one obviously works for OpenMP (omp) only. For TBB and SYCL, you will have to alter the Python script, as you cannot set the number of cores used through OMP_NUM_THREADS.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#!/bin/bash</span></div>
<div class="line"><span class="preprocessor">#SBATCH --job-name=upscaling</span></div>
<div class="line"><span class="preprocessor">#SBATCH -p multi</span></div>
<div class="line"><span class="preprocessor">#SBATCH --nodes=1</span></div>
<div class="line"><span class="preprocessor">#SBATCH -n 1</span></div>
<div class="line"><span class="preprocessor">#SBATCH -c 128</span></div>
<div class="line"><span class="preprocessor">#SBATCH --time=48:00:00</span></div>
<div class="line"><span class="preprocessor">#SBATCH --mail-type=END</span></div>
<div class="line"><span class="preprocessor">#SBATCH --mail-user=tobias.weinzierl@durham.ac.uk</span></div>
<div class="line"><span class="preprocessor">#SBATCH --array=1,2,4,8,16,24,32,40,48,56,64,80,96,128</span></div>
<div class="line"> </div>
<div class="line">source /etc/profile.d/modules.sh</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># adopt to your build/system</span></div>
<div class="line"><span class="keyword">module</span> purge</div>
<div class="line">module load oneapi/2022.2</div>
<div class="line">export FLAVOUR_NOCONFLICT=1</div>
<div class="line">module load gcc</div>
<div class="line">module load intelmpi</div>
<div class="line">export I_MPI_CXX=icpx</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"># switch to tbb or sycl</div>
<div class="line">export PREFIX=omp </div>
<div class="line">export TREES=8</div>
<div class="line"> </div>
<div class="line">export THREADS=$SLURM_ARRAY_TASK_ID</div>
<div class="line"> </div>
<div class="line"># this is how things work with OpenMP. Will be different for TBB and</div>
<div class="line"># SYCL where you might have to adopt the underlying Python script.</div>
<div class="line">export OMP_NUM_THREADS=$THREADS</div>
<div class="line">export OMP_PROC_BIND=close</div>
<div class="line"> </div>
<div class="line">export RESULTS_FOLDER=results-$THREADS-threads</div>
<div class="line"> </div>
<div class="line">mkdir $RESULTS_FOLDER</div>
<div class="line">for CELL_SIZE in 1.8 0.6 0.1</div>
<div class="line">do</div>
<div class="line">  for SCHEDULER in native subtasks subtasks-and-kernel-parallelisation</div>
<div class="line">  do</div>
<div class="line">    OUTPUT=$PREFIX-without-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    echo run $OUTPUT </div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt</div>
<div class="line"> </div>
<div class="line">    OUTPUT=$PREFIX-with-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    echo run $OUTPUT</div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt</div>
<div class="line">  done</div>
<div class="line">done</div>
</div><!-- fragment --><p>I use another script to acquire multi-node data:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#!/bin/bash</span></div>
<div class="line"><span class="preprocessor">#SBATCH --job-name=upscaling</span></div>
<div class="line"><span class="preprocessor">#SBATCH -p multi</span></div>
<div class="line"><span class="preprocessor">#SBATCH --nodes=1</span></div>
<div class="line"><span class="preprocessor">#SBATCH -n 1</span></div>
<div class="line"><span class="preprocessor">#SBATCH -c 128</span></div>
<div class="line"><span class="preprocessor">#SBATCH --time=48:00:00</span></div>
<div class="line"><span class="preprocessor">#SBATCH --mail-type=END</span></div>
<div class="line"><span class="preprocessor">#SBATCH --mail-user=tobias.weinzierl@durham.ac.uk</span></div>
<div class="line"><span class="preprocessor">#SBATCH --array=1,2,4,8,16,24,32,40,48,56,64,80,96,128</span></div>
<div class="line"> </div>
<div class="line">source /etc/profile.d/modules.sh</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># adopt to your build/system</span></div>
<div class="line"><span class="keyword">module</span> purge</div>
<div class="line">module load oneapi/2022.2</div>
<div class="line">export FLAVOUR_NOCONFLICT=1</div>
<div class="line">module load gcc</div>
<div class="line">module load intelmpi</div>
<div class="line">export I_MPI_CXX=icpx</div>
<div class="line"> </div>
<div class="line"># switch to tbb or sycl</div>
<div class="line">export PREFIX=omp</div>
<div class="line">export TREES=8</div>
<div class="line"> </div>
<div class="line">export RESULTS_FOLDER=results-$SLURM_NTASKS-nodes</div>
<div class="line"> </div>
<div class="line">mkdir $RESULTS_FOLDER</div>
<div class="line">for CELL_SIZE in 1.8 0.6 0.1</div>
<div class="line">do</div>
<div class="line">  for SCHEDULER in native subtasks subtasks-and-kernel-parallelisation</div>
<div class="line">  do</div>
<div class="line">    OUTPUT=$PREFIX-without-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    echo run $OUTPUT </div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt</div>
<div class="line"> </div>
<div class="line">    OUTPUT=$PREFIX-with-amr-$SCHEDULER-$TREES-trees-$CELL_SIZE</div>
<div class="line">    echo run $OUTPUT</div>
<div class="line">    ./$OUTPUT &gt; $RESULTS_FOLDER/$OUTPUT.txt</div>
<div class="line">  done</div>
<div class="line">done</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md696"></a>
Data gathering</h3>
<p>The script distributes the data into several subdirectories. We have to collocate them into one archive per measurement and then we can apply our out-of-the-box scripts:</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PREFIX=omp </div>
<div class="line"><span class="keyword">export</span> TREES=8</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">for</span> SCHEDULER in native subtasks subtasks-and-kernel-parallelisation</div>
<div class="line"><span class="keywordflow">do</span></div>
<div class="line">  rm $PREFIX-$SCHEDULER-without-amr-$TREES-trees.tar.gz</div>
<div class="line">  rm $PREFIX-$SCHEDULER-with-amr-$TREES-trees.tar.gz</div>
<div class="line">  </div>
<div class="line">  tar -cf $PREFIX-$SCHEDULER-without-amr-$TREES-trees.tar --files-from /dev/null</div>
<div class="line">  tar -cf $PREFIX-$SCHEDULER-with-amr-$TREES-trees.tar    --files-from /dev/null</div>
<div class="line"> </div>
<div class="line">  <span class="keywordflow">for</span> THREADS in 1 2 4 8 16 24 32 40 48 56 64 80 96 128</div>
<div class="line">  <span class="keywordflow">do</span></div>
<div class="line">    cp results-$THREADS-threads/$PREFIX-without-amr-$SCHEDULER-$TREES-trees.txt $THREADS-threads.txt</div>
<div class="line">    tar -rf $PREFIX-$SCHEDULER-without-amr-$TREES-trees.tar $THREADS-threads.txt</div>
<div class="line">    cp results-$THREADS-threads/$PREFIX-with-amr-$SCHEDULER-$TREES-trees.txt $THREADS-threads.txt</div>
<div class="line">    tar -rf $PREFIX-$SCHEDULER-with-amr-$TREES-trees.tar    $THREADS-threads.txt</div>
<div class="line">  done</div>
<div class="line">  </div>
<div class="line">  gzip $PREFIX-$SCHEDULER-without-amr-$TREES-trees.tar</div>
<div class="line">  gzip $PREFIX-$SCHEDULER-with-amr-$TREES-trees.tar</div>
<div class="line">done</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md697"></a>
Visualisation</h3>
<p>Get the tar archives. After that, we can use the out-of-the-box Peano scripts to generate the plots</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> PREFIX=omp</div>
<div class="line"><span class="keyword">export</span> TREES=8</div>
<div class="line"> </div>
<div class="line">OUTPUT=$PREFIX-$TREES-trees-without-amr</div>
<div class="line">python3 ../../../../python/<a class="code hl_namespace" href="../../dd/d6c/namespaceexahype2.html">exahype2</a>/postprocessing/<a class="code hl_namespace" href="../../de/d73/namespaceplot.html">plot</a>-scaling.py --max-cores-per-rank=-1 --log-x --log-y --output $OUTPUT \</div>
<div class="line">  --label <span class="stringliteral">&quot;native tasking, subtasks, subtasks and parallel kernels&quot;</span> --title <span class="stringliteral">&quot;No AMR&quot;</span> \</div>
<div class="line">  $PREFIX-native-without-amr-$TREES-trees.tar.gz \</div>
<div class="line">  $PREFIX-subtasks-without-amr-$TREES-trees.tar.gz \</div>
<div class="line">  $PREFIX-subtasks-and-kernel-parallelisation-without-amr-$TREES-trees.tar.gz</div>
<div class="line"> </div>
<div class="line"><span class="keyword">export</span> OUTPUT=$PREFIX-$TREES-trees-with-amr</div>
<div class="line">python3 ../../../../python/<a class="code hl_namespace" href="../../dd/d6c/namespaceexahype2.html">exahype2</a>/postprocessing/<a class="code hl_namespace" href="../../de/d73/namespaceplot.html">plot</a>-scaling.py --max-cores-per-rank=-1 --log-x --log-y --output $OUTPUT \</div>
<div class="line">  --label <span class="stringliteral">&quot;native tasking, subtasks, subtasks and parallel kernels&quot;</span> --title <span class="stringliteral">&quot;AMR, patch size 3, cell size 1.8&quot;</span> \</div>
<div class="line">  $PREFIX-native-without-amr-$TREES-trees.tar.gz \</div>
<div class="line">  $PREFIX-subtasks-without-amr-$TREES-trees.tar.gz \</div>
<div class="line">  $PREFIX-subtasks-and-kernel-parallelisation-without-amr-$TREES-trees.tar.gz</div>
<div class="ttc" id="anamespaceplot_html"><div class="ttname"><a href="../../de/d73/namespaceplot.html">plot</a></div><div class="ttdoc">-lift-drop-statistics</div></div>
</div><!-- fragment --><p>which clearly showcase that the kernel parallelisation pays off even though the overall scalability is poor with the present rather coarse mesh:</p>
<h1><a class="anchor" id="autotoc_md698"></a>
Production runs</h1>
<p>Han's original setup uses the full-blown CCZ4 setup with</p>
<div class="fragment"><div class="line">python3 <a class="code hl_namespace" href="../../dc/db2/namespaceccz4.html">ccz4</a>.py -ext adm -impl fd4-rk1-adaptive -s single-puncture -maxh 0.4 -minh 0.04 -ps 6 -plt 0.5 -et 100 -exn sbh27 --domain_r 9.0 --ReSwi 7 -cfl 0.1 -outdir ./ --KOSigma 8.0 -sommerfeld</div>
</div><!-- fragment --><p>and aims for a final time of at least 46. We mirror these properties in the following configurations:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Name   </th><th class="markdownTableHeadNone">Cell size   </th><th class="markdownTableHeadNone">Limiter patch size   </th><th class="markdownTableHeadNone">End time   </th><th class="markdownTableHeadNone">Plot   </th><th class="markdownTableHeadNone">AMR levels/FV patches   </th><th class="markdownTableHeadNone">Required nodes   </th><th class="markdownTableHeadNone">Call    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Small test with vis   </td><td class="markdownTableBodyNone">1.0   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">60.0   </td><td class="markdownTableBodyNone">yes   </td><td class="markdownTableBodyNone">2 (h_min=0.111111) / 7   </td><td class="markdownTableBodyNone">1 (around 5.8% of mem)   </td><td class="markdownTableBodyNone">python3 <a class="el" href="../../d6/d20/convergence-study_8py.html">convergence-study.py</a> -plot -cs 1.0 -s fd4-rk1-limited-ps-6 -et 60.0    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Medium test with vis   </td><td class="markdownTableBodyNone">0.5   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">60.0   </td><td class="markdownTableBodyNone">yes   </td><td class="markdownTableBodyNone">3 (h_min=0.037037) / 7   </td><td class="markdownTableBodyNone">1 (around 40% of mem)   </td><td class="markdownTableBodyNone">python3 <a class="el" href="../../d6/d20/convergence-study_8py.html">convergence-study.py</a> -plot -cs 0.5 -s fd4-rk1-limited-ps-6 -et 60.0    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Large test with vis   </td><td class="markdownTableBodyNone">0.1   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">60.0   </td><td class="markdownTableBodyNone">yes   </td><td class="markdownTableBodyNone">4 (h_min=0.0123457) / 33   </td><td class="markdownTableBodyNone">1 (around 30% of mem)*   </td><td class="markdownTableBodyNone">python3 <a class="el" href="../../d6/d20/convergence-study_8py.html">convergence-study.py</a> -plot -cs 0.1 -s fd4-rk1-limited-ps-6 -et 60.0    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">------------------&mdash;   </td><td class="markdownTableBodyNone">----&mdash;   </td><td class="markdownTableBodyNone">-----------------&mdash;   </td><td class="markdownTableBodyNone">-------&mdash;   </td><td class="markdownTableBodyNone">------&mdash;   </td><td class="markdownTableBodyNone">-----------------------&mdash;   </td><td class="markdownTableBodyNone">---------------------&mdash;   </td><td class="markdownTableBodyNone">-----&mdash;    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Production test 0   </td><td class="markdownTableBodyNone">0.05   </td><td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">60.0   </td><td class="markdownTableBodyNone">yes   </td><td class="markdownTableBodyNone">4   </td><td class="markdownTableBodyNone">x   </td><td class="markdownTableBodyNone">python3 <a class="el" href="../../d6/d20/convergence-study_8py.html">convergence-study.py</a> -cs 0.05 -s fd4-rk1-limited-ps-6 -et 60.0   </td></tr>
</table>
<dl class="todo"><dt><b><a class="el" href="../../dd/da0/todo.html#_todo000053">Todo</a></b></dt><dd>The calls above are not valid anymore. See benchmark docu further down which works.</dd></dl>
<p>It is clear that the excessive use of AMR here ensures that no enclave tasks are left anymore.</p>
<p>I found that OpenMP is comparatively slow. TBB does a way nicer job. I therefore recommend to use TBB in this case for the benchmarking.</p>
<h1><a class="anchor" id="autotoc_md699"></a>
Code remarks (FD4-FV scheme)</h1>
<p>Even simple initial conditions can make our higher-order Finite Differences solver fail: The higher order solution representation is not capable to resolve shocks properly (or steep gradients), and the solution therefore starts to oscillate. At the same time, experiments with Finite Volumes yield solutions which a subject to very strong numerical diffusion. The solution quality is not good. The black hole disappears.</p>
<p>There are two fundamental approaches to tackle this dilemma: On the one hand, we can introduce artificial damping terms, i.e. numerical diffusion, in the FD4 scheme. In the context of Finite Differences, this is usually done via Kreiss-Oliger (KO) dissipation. ExaHyPE's FD4 scheme indeed supports KO term. In the present case study, we however switch them off! Instead, we accept that both FD4 and FV have their pros and cons and try to use each solver where it unfolds its full potential.</p>
<dl class="todo"><dt><b><a class="el" href="../../dd/da0/todo.html#_todo000054">Todo</a></b></dt><dd>Remove the KO terms here</dd></dl>
<div class="image">
<img src="../../two-different-solvers.png" alt=""/>
</div>
<p>The image above illustrates our concept: There's an FD4 solver which computes the solution in the whole domain. This solution is is illustrated via the horizontal cut. In an area around the black hole (cross-shaped here; we visualise a slice through this domain), an additional Finite Volume solver is active. In each time step, the FD4 solver sets the boundary conditions of the Finite Volume solver. Those are the dark blue cells around the Finite Volume patches. With these coupling boundary conditions and global Sommerfeld conditions for the FD4 scheme, both solvers advance in time by one time step. After that one, the Finite Volume scheme overwrites the FD4 scheme in points which are covered by both numerical schemes (restriction).</p>
<p>This coupling strategy follows <a class="el" href="../../da/d8c/tutorials_exahype2_coupling.html">the default coupling schema</a> of ExaHyPE. Different to the generic coupling recipes there, we let the higher-order solver cover the whole domain. As FV only will be used in a tiny region, this overhead is acceptable. Furthermore, we do not use any fancy colouring to decide which solver is active where. We hard-code this information, as we know where our black hole is.</p>
<p>Mathematically, the Finite Volume solver serves as a priori limiter to the FD4 solution. It is a priori, as we do not wait for the FD4 solution to determine if we need Finite Volumes. We overwrite always. For the realisation, we try to keep as much coupling logic as possible within the FD4 scheme: The limiter knows where to compute, but all the remaining logic is realised with the FD4 solver, as this one knows what the data layout of FD4 is. Furthermore, this separation of responsibilities allows us, in theory, to use the same limiter with RKDG as well.</p>
<h2><a class="anchor" id="autotoc_md700"></a>
Time step size</h2>
<p>As we combine solvers, we have to ensure that their time step sizes match. This means that the Finite Volume patch size has to be calibrated with \( p^{2}=16 \) relative to the high order's patch size. If they had the same mesh size, the higher order schemes would take significantly smaller time step sizes. However, we want to havee the same spatial and temporal accuacy, so we need a smaller mesh size for the Finite Volume scheme. The file benchmarks/exahype2/ccz4/single-black-hole/convergence-study.py and the solvers within applications/exahype2/ccz/CCZ4Solver.py hold further details.</p>
<p>As the FD4 scheme works with subpatches per octree cell (octant) of size \( 3^d \) or \( 6^d \) respectively, we get Finite Volume patches around the centre which are of the size \( (3\cdot 16)^d = 48^d \) or \( (6\cdot 16)^d = 96^d \). They host up to 884736 volumes. They are large.</p>
<p>Although we recalibrate the patch sizes to take the different spatial discretisation orders into account, this not yet ensure that both the Finite Differences and Finite Volume solver run in-sync. The Finite Volume scheme will be subject to a higher numerical dissipation, while the Finite Differences scheme might run into numerical oscillations/instabilities. At the same time, the limiter will always run at a significantly higher resolution than its higher-order counterpart and capture the singularity. It might therefore happen that it actually yields a smaller admissibile time step size. Therefore, it remains important that both solvers agree on a common time step size after each time step, even though both solvers should come up with an admissible time step size of roughly the same order.</p>
<p>We try to keep all coupling and other logic within the higher order solver. Our intention is to have a generic limiter which can work with multiple solvers, once we have multiple higher order schemes. As a consequence, I introduced a new <a class="el" href="../../d0/d46/classbenchmarks_1_1exahype2_1_1ccz4_1_1CCZ4SBH__FV.html#a9e377298d6588adf14541cd09ac58878" title="Overwrite limiters time step size.">benchmarks::exahype2::ccz4::CCZ4SBH_FV::reduceAdmissibleTimeStepSize()</a> which allows us to reset the admissible time step size. Next, each higher order solver overwrites startTimeStep(), computes the minimum over the available time step sizes, and sets this minimum as own admissible size as well as the admissible time step size of the limiter.</p>
<h2><a class="anchor" id="autotoc_md701"></a>
The Finite Volume solver</h2>
<p>Our FV solver is, through various inheritance levels, a subclass of peano.exahype2.solvers.fv.EnclaveTasking which in turn inherits from peano.exahype2.solvers.fv.FV. The solver is a text-book FV scheme, with one major added functionality: We add the implementation the routines <a class="el" href="../../d0/d46/classbenchmarks_1_1exahype2_1_1ccz4_1_1CCZ4SBH__FV.html#aa395e8acf933a2ccd2f3e1e14412904c" title="Is octant area overlapping with BH impact area.">benchmarks::exahype2::ccz4::CCZ4SBH_FV::isCellOverlappingWithBHImpactArea()</a>, <a class="el" href="../../d0/d46/classbenchmarks_1_1exahype2_1_1ccz4_1_1CCZ4SBH__FV.html#a4dce9a90b00ad8e66a376e553c001eb6" title="Check two adjacent octants.">benchmarks::exahype2::ccz4::CCZ4SBH_FV::areBothAdjacentCellsOverlappingWithBHImpactArea()</a>, and their cousins. That is, we implement the actual logic where to apply the limiter within the C++ class.</p>
<p>Within the Python code, we follow <a class="el" href="../../da/d8c/tutorials_exahype2_coupling.html">localisation recommendations for solver coupling</a> and overwrite the routines</p>
<ul>
<li>_store_cell_data_default_guard()</li>
<li>_load_cell_data_default_guard()</li>
<li>_provide_cell_data_to_compute_kernels_default_guard</li>
</ul>
<p>such that only data within a certain radius around the black hole are actually held. An analogous scheme holds for the faces. For the implementation of these guards, we rely on the previously introduced <a class="el" href="../../d0/d46/classbenchmarks_1_1exahype2_1_1ccz4_1_1CCZ4SBH__FV.html#aa395e8acf933a2ccd2f3e1e14412904c" title="Is octant area overlapping with BH impact area.">benchmarks::exahype2::ccz4::CCZ4SBH_FV::isCellOverlappingWithBHImpactArea()</a> and <a class="el" href="../../d0/d46/classbenchmarks_1_1exahype2_1_1ccz4_1_1CCZ4SBH__FV.html#a4dce9a90b00ad8e66a376e553c001eb6" title="Check two adjacent octants.">benchmarks::exahype2::ccz4::CCZ4SBH_FV::areBothAdjacentCellsOverlappingWithBHImpactArea()</a>.</p>
<p>Their implementation is straightforward: We store these cells which overlap with this black hole influence region. Consequently, we store only faces persistently which have a cell left and right which actually holds data. Finally, we have to create faces temporarily - similar to hanging faces - around this Finite Volume area of interest. We need those as the Finite Volume solver will, for example, project its solution onto a patch's boundaries, even though we can throw them away afterwards, i.e. we do not store them.</p>
<p>It is the routine peano.exahype2.solvers.fv.FV.create_action_sets() which configures all the dynamic behaviour. After calling the superclass implementation, we modifiy the two guards _action_set_update_cell.guard and _action_set_merge_enclave_task_outcome.guard to ensure that the solution is also only computed on those cells which hold meaningful data. Without those guards, the solver would invoke the compute kernels everywhere, even though the majority of the mesh holds only garbage solution which is neither stores nor loaded persistently in-between two mesh traversals.</p>
<p>Finally, we set the priorities of the Finite Volume solver up. By default, any enclave tasks has the same (default) priority. We know however that the Finite Volume tasks are extremely expensive - notably compared to their higher order cell countersparts. In an ideal world, all enclave tasks should be postponed into a queue throughout the grid traversal besides the Finite Volume tasks which should go straight onto a core or the GPU. To re-prioritise, we add</p>
<div class="fragment"><div class="line">self.enclave_task_priority = <span class="stringliteral">&quot;tarch::multicore::Task::DefaultPriority+1&quot;</span></div>
</div><!-- fragment --><p>to the constructor.</p>
<h2><a class="anchor" id="autotoc_md702"></a>
The FD4 solver</h2>
<h3><a class="anchor" id="autotoc_md703"></a>
FD4-FV coupling (projection)</h3>
<p>To realise the coupling, we have to augment the FD4 solver by some additional pre- and post-processing steps:</p>
<ol type="1">
<li>We add Sommerfeld boundary conditions. This is important, as the FD4 solver will be responsible to simulate the solution close to the domain boundaries.</li>
<li><p class="startli">The primary solver takes its reconstructed solution, i.e. the Q values within the patch plus its halo (of size 3 for FD) and projects this information down into the FV solver. This should happen</p><ul>
<li>before the FV solver kicks off</li>
<li>using consistent FD4 data within the cell and on the faces</li>
</ul>
<p class="startli">I initially thought that the projection could be triggered by the FD4 solver after each time step. However, this is not a good idea, as we do not have consistent face data at this point. We however need the faces to have proper halo information to be able to interpolate correctly. So it has be done before the solver kicks off.</p>
<p class="startli">Associating it with the FD4 solver's preprocess_reconstructed_solution would be convenient, as these data hold the halo information already, i.e. they provide access to the patch data plus its halo. However, plugging into this routine makes assumptions on the evaluation order: We have to know that the FV code has not started any calculation yet. It is more convenient to let the coupling happen within either solver's _action_set_preprocess_solution action set as a preamble of its actual time step. This way, it will definitely be kicked off before we actually run into the timestepping.</p>
</li>
<li>The preprocessing has to be of type exahype2.solvers.rkfd.actionsets.PreprocessReconstructedSolutionWithHalo as we need the area around the FD4 patch to interpolate into all the "edge" volumes of the Finite Volume patch. This PreprocessReconstructedSolutionWithHalo is itself a subclass of peano4.toolbox.blockstructured.ReconstructPatchAndApplyFunctor and reconstructs the FD4 solver's halo (temporarily) into a field called oldQWithHalo before it invokes a functor on the reconstructed data.</li>
<li>We use oldQWithHalo to project the solution down into a temporary FV patch. The temporary patch is called interpolatedFVDataWithHalo, and the actual interpolation is realised through <a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#a7d2a453be5cf6a74fa77d93792a7ee74">toolbox::blockstructured::interpolateCellDataAssociatedToVolumesIntoOverlappingCell_linear()</a>. At the end of the functor, we free the interpolatedFVDataWithHalo again.</li>
<li>Before we free it, we take interpolatedFVDataWithHalo and map it onto the FV faces for those faces which are not in-between two FV cells. For this, we utilise <a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#ad70e2aac33cc0a2afc141faa844563b7" title="Take elements from the halo and project them onto the face.">toolbox::blockstructured::projectPatchHaloOntoFaces</a>. This routine expects 2d face data always. For the faces in-between two FV patches which we don't want to overwrite, we pass in some temporary arrays just to make the function work, but we throw these temporary face data away immediately afterwards.</li>
</ol>
<p>Once the fifth step has terminated, the Finite Volume solver's patches have a properly befilled QNew on the faces. This QNew usually holds the halo copy from neighbouring patches. Where these neighbouring patches do not exist in the FV scheme, we now have interpolated data from the FD4 solution.</p>
<p>Our scheme couples the FD4 solver to the Finite Volume scheme over the faces. However, we realise the coupling volumetric, i.e we project volumetric data from FD4 onto FV data (temporarily) and from there project the volumetric Finite Volume representation again onto the faces. This not particularly elegant, and there might be way faster realisations which omit this temporary volumetric step, but is a realisation which can be implemented with the on-board routines and the logic of it is rather clear.</p>
<h3><a class="anchor" id="autotoc_md704"></a>
FV-FD4 coupling (restriction)</h3>
<p>The coupling from the Finite Volume scheme to FD4 in contrast is a real volumetric coupling: We overwrite the FD4's self._action_set_postprocess_solution with an instance of exahype2.solvers.rkfd.actionsets.PatchWisePostprocessSolution. This postprocessing is be executed after both the Finite Volume and the Differences scheme have updated their patch. This is ensured by the fact that postprocessing steps always plug into touchCellLastTime (cmp <a class="el" href="../../da/d1b/peano_action_sets.html">Peano's generic discussion of the order of events</a>).</p>
<p>For the realisation, we employ the built-in routines. For example, we call <a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#a542ce918ed013ad8ea8b8cf5d12bec63" title="This routine should be used if a cell hosts two sets of unknowns.">toolbox::blockstructured::restrictCellIntoOverlappingCell_inject()</a> for every cell which holds Finite Volume data, i.e. overlaps with the black hole. This is slightly different to <a class="el" href="../../da/d8c/tutorials_exahype2_coupling.html">ExaHypE's generic coupling sketch</a>, where I recommend to have at least one whole cell overlap between any two solvers: I do not only inject data from Finite Volume patches back which are completely surrounded by further FV patches. It seemed to me to be a waste of compute power to do this. Rather make the black hole influence area smaller.</p>
<p>We have played around with different restriction variants:</p>
<ul>
<li><a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#a542ce918ed013ad8ea8b8cf5d12bec63" title="This routine should be used if a cell hosts two sets of unknowns.">toolbox::blockstructured::restrictCellIntoOverlappingCell_inject()</a>: If we use a plain injection, we get a reasonably stable coupling, but the solution starts to show a kink after a while where the FD4 domain meets the limiter area. This effect can be mitigated by makind the FV domain larger, but this leads to stronger numerical dissipation and therefore harms the solution.</li>
<li><a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#a4e1026ebdef78b655aa5849adc61dc08" title="Flavour of restrictCellIntoOverlappingCell_inject() where we inject the solution but then take the av...">toolbox::blockstructured::restrictCellIntoOverlappingCell_inject_and_average()</a>: This variant accepts that FD4 delivers a reasonable numerical answer (albeit likely unstable) and uses the FV solution to drag it into a different solution, i.e. to correct it, as we always take the average of both solvers and continue to work with this one.</li>
<li>Finally, we can use a hybrid of the two worlds, where the very centre of the domain is determined by FV only, but the area around it results from averaging.</li>
</ul>
<h1><a class="anchor" id="autotoc_md705"></a>
Optimisation</h1>
<h2><a class="anchor" id="autotoc_md706"></a>
Domain decomposition</h2>
<p>I found that using more than 8 trees per rank slows down the calculations massively and introduces an enormous overhead, when we do the domain partitioning. Therefore, I constrain the maximum number of initial trees to 8 per rank, and then I also introduce a minimal tree size of 100. As the documentation of <a class="el" href="../../d0/d0e/classexahype2_1_1LoadBalancingConfiguration.html#a617dbf27493e7779231f61608ed68d84" title="Configure load balancing.">exahype2::LoadBalancingConfiguration::LoadBalancingConfiguration()</a> clarifies, this minimal tree size is not used for the initial decomposition (this is where the 8 steps in), but it is used afterwards.</p>
<h2><a class="anchor" id="autotoc_md707"></a>
High level code tuning</h2>
<p>The lionshare of the compute time is burnt within the Finite Volume patches. I followed a series of optimisation steps to get this part of the code faster:</p>
<ol type="1">
<li>I switched to a <a class="el" href="../../d7/dfe/page_exahype_performance_optimisation.html">heap-based</a> data storage.</li>
<li>I notified the solver that <a class="el" href="../../d1/d26/page_exahype_gpu.html">all the ncp, eigenvalue and source terms are side effect-free</a>. That is, they do not alter any global state and solely the patch outcome.</li>
<li>I alter the generated Makefile manually. That is, I replace the solver part with <div class="fragment"><div class="line">solver:  $(CXX_OBJS) $(FORTRAN_OBJS)</div>
<div class="line">        rm tasks<span class="comment">/*.o</span></div>
<div class="line"><span class="comment">        $(CXX) $(CXXFLAGS) -qopt-report=3 -c tasks/CCZ4SBH_FD4EnclaveTask.cpp -o tasks/CCZ4SBH_FD4EnclaveTask.o</span></div>
<div class="line"><span class="comment">        $(CXX) $(CXXFLAGS) -qopt-report=3 -c tasks/CCZ4SBH_FVEnclaveTask.cpp  -o tasks/CCZ4SBH_FVEnclaveTask.o</span></div>
<div class="line"><span class="comment">        $(CXX) $(FORTRAN_MODULE_OBJS) $(FORTRAN_OBJS) $(CXX_OBJS) $(LDFLAGS) $(CU_OBJS) $(LIBS) -o peano_sbh_2.0</span></div>
</div><!-- fragment --> This follows <a class="el" href="../../da/d8a/page_peano_performance_optimisation.html">Peano's recommendations</a> how to obtain meaningful optimisation reports. However, it will result in many warnings, as the compiler will be unable to inline and consequently vectorise the required static functions.</li>
</ol>
<h2><a class="anchor" id="autotoc_md708"></a>
Concurrency analysis with default task orchestration</h2>
<p>When we visualise the CPU occupation, we get an image similar to the one below.</p>
<div class="image">
<img src="../../vtune00.png" alt=""/>
</div>
<p>One time step starts at 115s. We have four threads here. Their partitions are not perfectly balanced. This leads to an oversubscribed thread 3. The primary sweep is relatively cheap, as most patch updates are deployed into tasks and hence not computed. Arround 118s, all four threads start the second grid sweep which again is very short besides on the fourth thread. It also remains a mystery why the heavy Finite Volume patch updates, which are all clearly visible (there are 7 of them), all are executed sequentially.</p>
<p>Things start to make sense once we study the result of tarch::multicore::orchestration::createDefaultStrategy() and run VTune once more with native threading. The default implementation always tries to hold back 16 tasks to be able to fuse them on the GPU. Unfortunately, our expensive Finite Volume patches are among these 16. Therefore, they are really only processed when a thread requests their outcome. The native task realisation maps all enclave tasks onto proper (OpenMP) tasks</p>
<div class="image">
<img src="../../vtune01.png" alt=""/>
</div>
<p>and hence does a significantly better job. Finally, also some of the patch updates of the limited regions are computed in parallel. Still, we see those massive imbalances.</p>
<p>Tracing with Otter confirms that the Finite Volume and FD4 patches are spawned as enclave tasks. However, they drop in in totally random order and the expensive Finite Volume tasks run risk not to run in parallel but to be sequentialised. I hence introduce a tailored task orchestration:</p>
<ul>
<li>Introduce a new class MulticoreOrchestration. It inherits from tarch::multicore::orchestration::Strategy.</li>
<li>Create an instance of this class and invoke tarch::multicore::setOrchestration() to activate it.</li>
<li>Add the file to the project, such that the makefile picks it up: <div class="fragment"><div class="line">project.set_load_balancing( <span class="stringliteral">&quot;tarch::multicore::orchestration::Hardcoded::createNative()&quot;</span> )</div>
</div><!-- fragment --></li>
</ul>
<p>Consult the documentation of the MulticoreOrchestration for information on its behaviour.</p>
<h2><a class="anchor" id="autotoc_md709"></a>
Optimise the actual compute kernels</h2>
<p>We see that the majority of the runtime is now spent in the interpolation of the FD4 solver. The higher order FD scheme is too expensive and notably serialises things. Studying the call stack reveals that this interpolation does not occur at the AMR boundaries, but it is the interpolation within the limited region which slows down the calculation. Therefore, I started to tune the routine <a class="el" href="../../d1/d28/namespacetoolbox_1_1blockstructured.html#a7d2a453be5cf6a74fa77d93792a7ee74">toolbox::blockstructured::interpolateCellDataAssociatedToVolumesIntoOverlappingCell_linear()</a>. All the (OpenMP) parallelisation in there is a result of this benchmark. These optimisations are to be enabled explicitly by the scheduler.</p>
<p>I next try to do the same thing with the FV kernel. Here, we follow the recipes of <a class="el" href="../../d7/dfe/page_exahype_performance_optimisation.html">the page describing how to make our compute kernels use all cores</a>. In line with the description in there, we exploit the fact that we know that all patches can be updated in an embarrassingly parallel way. Furthermore, we know that literally all patches will be stateless. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../index.html">Peano</a></li><li class="navelem"><a class="el" href="../../d3/d82/page_exahype2_home.html">ExaHyPE 2</a></li><li class="navelem"><a class="el" href="../../d4/dad/page_exahype_benchmarks.html">Benchmarks</a></li>
    <li class="footer">Generated on Tue Jul 1 2025 11:29:01 for Peano by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
