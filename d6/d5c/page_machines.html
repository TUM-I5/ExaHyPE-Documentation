<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="icon" href="../../Peano-icon.png" type="image/x-icon" />
<title>Peano</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript" src="../../doxygen-awesome-tabs.js"></script>
<script type="text/javascript" src="../../toggle-alternative-theme.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
    DoxygenAwesomeTabs.init()
</script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../custom.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
<link href="../../custom-alternative.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<!-- https://bryce.io/gitlab-corners/ -->
<style>.gitlab-corner-wrapper{overflow:hidden;width:100px;height:100px;position:absolute;top:0;right:0}.gitlab-corner{position:absolute;top:-16px;right:-50px;transform:rotate(45deg);background:#333;border:44px solid #333;border-bottom:none;border-top:#333 solid 16px}.gitlab-corner svg{width:60px;height:60px;margin-bottom:-4px}.cls-1{fill:#fc6d26}.cls-2{fill:#e24329}.cls-3{fill:#fca326}.gitlab-corner:hover .cls-1{animation:cycle .6s}.gitlab-corner:hover .cls-2{animation:cycleMid .6s}.gitlab-corner:hover .cls-3{animation:cycleEnd .6s}@keyframes cycle{100%,15%,60%{fill:#fc6d26}30%,75%{fill:#e24329}45%,90%{fill:#fca326}}@keyframes cycleMid{100%,15%,60%{fill:#e24329}30%,75%{fill:#fca326}45%,90%{fill:#fc6d26}}@keyframes cycleEnd{100%,15%,60%{fill:#fca326}30%,75%{fill:#fc6d26}45%,90%{fill:#e24329}}@media (max-width:500px){.gitlab-corner:hover .cls-1,.gitlab-corner:hover .cls-2,.gitlab-corner:hover .cls-3{animation:none}.gitlab-corner .cls-1{animation:cycle .6s}.gitlab-corner .cls-2{animation:cycleMid .6s}.gitlab-corner .cls-3{animation:cycleEnd .6s}}</style><div class="gitlab-corner-wrapper"><a href="https://gitlab.lrz.de/hpcsoftware/Peano" class="gitlab-corner" aria-label="View source on GitLab"><svg id="logo_art" data-name="logo art" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 586 559"><g id="g44"><path id="path46" class="cls-1" d="M461.17,301.83l-18.91-58.12L404.84,128.43a6.47,6.47,0,0,0-12.27,0L355.15,243.64H230.82L193.4,128.43a6.46,6.46,0,0,0-12.26,0L143.78,243.64l-18.91,58.19a12.88,12.88,0,0,0,4.66,14.39L293,435,456.44,316.22a12.9,12.9,0,0,0,4.73-14.39"/></g><g id="g48"><path id="path50" class="cls-2" d="M293,434.91h0l62.16-191.28H230.87L293,434.91Z"/></g><g id="g56"><path id="path58" class="cls-1" d="M293,434.91,230.82,243.63h-87L293,434.91Z"/></g><g id="g64"><path id="path66" class="cls-3" d="M143.75,243.69h0l-18.91,58.12a12.88,12.88,0,0,0,4.66,14.39L293,435,143.75,243.69Z"/></g><g id="g72"><path id="path74" class="cls-2" d="M143.78,243.69h87.11L193.4,128.49a6.47,6.47,0,0,0-12.27,0l-37.35,115.2Z"/></g><g id="g76"><path id="path78" class="cls-1" d="M293,434.91l62.16-191.28H442.3L293,434.91Z"/></g><g id="g80"><path id="path82" class="cls-3" d="M442.24,243.69h0l18.91,58.12a12.85,12.85,0,0,1-4.66,14.39L293,434.91l149.2-191.22Z"/></g><g id="g84"><path id="path86" class="cls-2" d="M442.28,243.69h-87.1l37.42-115.2a6.46,6.46,0,0,1,12.26,0l37.42,115.2Z"/></g></svg></a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../Peano-icon.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Peano
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('d6/d5c/page_machines.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Reference Configurations for Some Machines</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#autotoc_md960">Hamilton</a><ul><li class="level2"><a href="#autotoc_md961">Older settings (not tested atm)</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md962">NCC</a><ul><li class="level2"><a href="#autotoc_md963">OpenMP with NVC++</a></li>
<li class="level2"><a href="#autotoc_md964">SYCL offloading with oneAPI</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md965">DINE</a></li>
<li class="level1"><a href="#autotoc_md966">MAD07 (Ice Lake)</a></li>
<li class="level1"><a href="#autotoc_md967">MAD08/MAD09 (Genoa)</a></li>
<li class="level1"><a href="#autotoc_md968">Grace Hopper</a></li>
<li class="level1"><a href="#autotoc_md969">SuperMUC-NG Phase 2</a></li>
<li class="level1"><a href="#autotoc_md970">AMD cloud machine</a></li>
<li class="level1"><a href="#autotoc_md971">Example: Local WSL Ubuntu 22.04</a></li>
<li class="level1"><a href="#autotoc_md972">Leonardo</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="autotoc_md960"></a>
Hamilton</h1>
<p><img src="https://nccadmin.webspace.durham.ac.uk/wp-content/themes/core/assets/img/theme/branding-assets/durham-university-logo.svg" alt="" style="pointer-events: none;" width="20%" class="inline"/></p>
<p>Hamilton 8 is Durham's internal supercomputer. It is a system powered by AMD EPYC processors. I nevertheless prefer the Intel toolchain on the machine.</p>
<p>Hamilton's default oneapi module is built against a GCC version which is too old and lacks important features within its standard library. Therefore, you have to manuall load the latest gcc. This is usually prevented by the system and leads to a conflict (so that you can't have multiple GCC versions loaded). We therefore have to disable conflict checks a priori. Eventually, I end up with</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> purge</div>
<div class="line">module load oneapi/2024.2</div>
<div class="line">export FLAVOUR_NOCONFLICT=1</div>
<div class="line">module load gcc/14.2</div>
<div class="line">module load intelmpi</div>
<div class="line">module load tbb/2022.0</div>
<div class="line"> </div>
<div class="line">export I_MPI_CXX=icpx</div>
</div><!-- fragment --><p>For the vectorisation, we recognise that we always need</p>
<div class="fragment"><div class="line">-Ofast -ffast-math</div>
</div><!-- fragment --><p>If you use mpiicpc, the MPI wrapper still refers to icpc even though icpc is officially deprecated. Therefore, I manually have to repoint it to icpx. The other options to do this (via additional script arguments, e.g.) all failed on this machine.</p>
<ul>
<li>TBB runs <div class="fragment"><div class="line">./configure CXX=icpx CC=icx <span class="stringliteral">&#39;CXXFLAGS=-O3 -ffast-math -mtune=native -march=native -fma -fomit-frame-pointer -std=c++20 -fno-exceptions -Wno-unknown-attributes -Wno-gcc-compat&#39;</span> LIBS=<span class="stringliteral">&quot;-ltbb&quot;</span> LDFLAGS=<span class="stringliteral">&quot;-L${TBBROOT}/lib&quot;</span> --enable-<a class="code hl_namespace" href="../../d2/df6/namespacemghype.html">mghype</a> --enable-exahype --enable-blockstructured --enable-finiteelements --with-multithreading=tbb_extension --enable-loadbalancing</div>
<div class="ttc" id="anamespacemghype_html"><div class="ttname"><a href="../../d2/df6/namespacemghype.html">mghype</a></div><div class="ttdoc">This file is part of the multigrid project within Peano 4.</div><div class="ttdef"><b>Definition</b> <a href="../../db/d6d/src_2mghype_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
</div><!-- fragment --></li>
</ul>
<h2><a class="anchor" id="autotoc_md961"></a>
Older settings (not tested atm)</h2>
<ul>
<li>MPI production runs <div class="fragment"><div class="line">./configure CC=icpx CXX=icpx CXXFLAGS=<span class="stringliteral">&quot;-Ofast -g -std=c++20 -mtune=native -march=native -fma -fomit-frame-pointer -qopenmp -Wno-unknown-attributes&quot;</span> LDFLAGS=<span class="stringliteral">&quot;-fiopenmp -g&quot;</span> --with-multithreading=omp --enable-exahype --enable-loadbalancing --enable-blockstructured --enable-particles --with-mpi=mpiicpc FC=gfortran</div>
</div><!-- fragment --></li>
<li>Performance analysis runs with single node tracing <div class="fragment"><div class="line"><span class="keyword">module</span> load vtune</div>
<div class="line">./configure CC=icpx CXX=icpx CXXFLAGS=&quot;-Ofast -g -std=c++20 -mtune=native -march=native -fma -fomit-frame-pointer -qopenmp -Wno-unknown-attributes -I${VTUNE_HOME}/vtune/latest/include&quot; LDFLAGS=&quot;-qopenmp -g -L${VTUNE_HOME}/vtune/latest/lib64&quot; LIBS=&quot;-littnotify&quot; --with-multithreading=omp --enable-exahype --enable-loadbalancing --enable-blockstructured --enable-particles --with-mpi=mpiicpc FC=gfortran --with-toolchain=itt</div>
</div><!-- fragment --></li>
<li>MPI performance analysis runs <div class="fragment"><div class="line"><span class="keyword">module</span> load vtune</div>
<div class="line">./configure CC=icpx CXX=icpx CXXFLAGS=&quot;-I${VTUNE_HOME}/vtune/latest/include -I${VT_ROOT}/include -Ofast -g -std=c++20 -mtune=native -march=native -fma -fomit-frame-pointer -qopenmp -Wno-unknown-attributes&quot; LDFLAGS=&quot;-qopenmp -g -L${VT_LIB_DIR} -L${VTUNE_HOME}/vtune/latest/lib64&quot; LIBS=&quot;-lVT ${VT_ADD_LIBS} -littnotify&quot; --with-multithreading=omp --enable-exahype --enable-loadbalancing --enable-blockstructured --enable-particles --with-mpi=mpiicpc FC=gfortran --with-toolchain=itac</div>
</div><!-- fragment --></li>
</ul>
<p>Further to these flags, I pause and resume the data collection manually in ExaHyPE and Swift. This is however something I do in the <a class="el" href="../../d4/d76/benchmarks_2other_2noh2d_2main_8cpp.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main()</a> routine of the respective applications.</p>
<h1><a class="anchor" id="autotoc_md962"></a>
NCC</h1>
<p>I recommend atm to use <code>gpu10</code>, <code>gpu11</code> or <code>gpu12</code>, i.e. the A100 machines. By default, I usually work with NVC++ on this cluster, but the OneAPI software stack should work, too.</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> load nsight-systems cuda llvm</div>
<div class="line">module load mvapich2/2.3.5-2</div>
<div class="line"> </div>
<div class="line">./configure --enable-exahype --enable-loadbalancing-toolbox --with-multithreading=omp --with-mpi=mpicxx --with-gpu=omp CXX=clang++ CXXFLAGS=&quot;-fopenmp -fopenmp-targets=nvptx64-nvidia-cuda&quot;</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md963"></a>
OpenMP with NVC++</h2>
<p>I use the setup</p>
<div class="fragment"><div class="line">./configure CXX=nvc++ CC=nvc++ CXXFLAGS=<span class="stringliteral">&quot;-O4 --std=c++17 -mp=gpu -gpu=cc80&quot;</span> LDFLAGS=<span class="stringliteral">&quot;-mp=gpu -gpu=cc80&quot;</span> --with-multithreading=omp --with-gpu=omp --enable-exahype --enable-blockstructured --enable-loadbalancing CPP=cpp FC=/apps/nvidia-hpc-sdk/Linux_x86_64/22.3/compilers/bin/nvfortran</div>
</div><!-- fragment --><p>on the A100 nodes.</p>
<p>We had some issues (compiler crashes) with NVC++ 2022.5. Those are filed with NVIDIA. For the time being, please revert to another compiler generation. Version 2022.3 works for example.</p>
<p>Some nodes (e.g. gpu3) have Titan XP which doesn't support OpenMP offloading; only GPUs with compute capability &gt;=70 can offload with OpenMP. You can check the GPU model with <code>nvidia-smi -L</code>.</p>
<p>Note that there is a bug in the NVIDIA software stack at the moment. Many runs will crash with a complaint about a lack of visible devices. Ensure hence that you set the following environment before you start your experiments:</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> CUDA_VISIBLE_DEVICES=0</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md964"></a>
SYCL offloading with oneAPI</h2>
<p>I used this to configure Peano with Intel's TBB enabled</p>
<div class="fragment"><div class="line">source /opt/intel/oneapi/setvars.sh</div>
<div class="line"><span class="keyword">module</span> load cuda</div>
<div class="line"> </div>
<div class="line">./configure CC=icx CXX=icpx LIBS=&quot;-ltbb&quot; LDFLAGS=&quot;-fsycl -fsycl-targets=nvptx64-nvidia-cuda,spir64 -Xsycl-target-backend=nvptx64-nvidia-cuda --cuda-gpu-arch=sm_80&quot; CXXFLAGS=&quot;-O3 -std=c++20 -fsycl -fsycl-targets=nvptx64-nvidia-cuda,spir64 -Xsycl-target-backend=nvptx64-nvidia-cuda --cuda-gpu-arch=sm_80&quot; --with-multithreading=tbb --enable-exahype --enable-blockstructured --enable-loadbalancing --with-gpu=sycl</div>
</div><!-- fragment --><p>Codeplay's website has some useful information on compiler flags. Here's a short explaination of the above SYCL related flags:</p>
<ul>
<li><code>-fsycl</code> tells the compiler to link SYCL libraries and makes it aware of SYCL code. It seems that Clang behaves slightly different to icpx, where you need <code>-lsycl</code> in the linker flags.</li>
<li><code>-fsycl-targets=</code> allows the compiler to generate code for different devices, e.g., different vendors, host or device.</li>
<li><code>-Xsycl-target-backend=</code> is required if you want to select a specific device architecture. For example, I put <code>--cuda-gpu-arch=sm_80</code> after it to compile for A100 with compute capability 8.0.</li>
</ul>
<p>It also needs at least 2023.0.0 version of oneAPI with Codeplay's nvidia GPU plugin which is not installed on NCC. Intel encourages the use of their own compiler, <code>icpx</code>. However, they use a lower precision by default in favour of performance, use <code>-fp-model</code> to change this behaviour.</p>
<p>I had linker errors about undefined referennces when building Peano with TBB. Just add the path to any relevant library if you experienced this.</p>
<p>When running the executable on the GPU, include <code>SYCL_DEVICE_FILTER=gpu</code> before the terminal command to explicitly tell SYCL to run the code on GPU. In the case of a runtime error, it is also useful to add <code>SYCL_PI_TRACE=2</code> to check where the error was raised.</p>
<h1><a class="anchor" id="autotoc_md965"></a>
DINE</h1>
<p><img src="https://www.dur.ac.uk/images/cosma/cosma_white.png" alt="" width="20%" class="inline"/></p>
<p>DINE (Durham Intelligent NIC Environment) is a small supercomputer attached to Cosma, which we use to prototype some of our algorithms. Access is through the Cosma loging nodes (login8.cosma.dur.ac.uk). As Cosma and DINE feature the same generation of AMD chips, you can compile on Cosma8 and ship the executable to DINE.</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> load git</div>
<div class="line">module load autoconf </div>
<div class="line">module load python</div>
<div class="line">module load intel_comp</div>
<div class="line">module load compiler-rt tbb compiler</div>
<div class="line">module load intel_mpi</div>
<div class="line">module load gnu_comp/13.1.0</div>
<div class="line">export I_MPI_CXX=icpx</div>
<div class="line">./configure --enable-exahype --enable-blockstructured --enable-loadbalancing --enable-particles CC=icx CXX=icpx --with-multithreading=omp --with-mpi=mpiicpc CXXFLAGS=&quot;-std=c++20 -qopenmp -funroll-loops -Ofast&quot;</div>
</div><!-- fragment --><p>There are a few things to consider whenever you use DINE:</p>
<ul>
<li>The default Python version usually is a little bit too old, so switching to a more recent Python package is reasonable.</li>
<li>Don't use the -xHost flag in configure. The resulting code will crash on DINE. You can use <div class="fragment"><div class="line">-march=native</div>
</div><!-- fragment --></li>
<li>Try not to dump data into the home directory, as this one is backe up and has a quota. DINE mounts the Cosma 5 data directory (/cosma5/data/do009/myaccount) which you should use to store data files.</li>
</ul>
<h1><a class="anchor" id="autotoc_md966"></a>
MAD07 (Ice Lake)</h1>
<p><img src="https://www.dur.ac.uk/images/cosma/cosma_white.png" alt="" width="20%" class="inline"/></p>
<p>mad07 is an IceLake server with Barlow Pass memory which is added to Cosma to facilitate benchmarking for the SKA project.</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> purge</div>
<div class="line"> </div>
<div class="line">module unload python</div>
<div class="line">module load python/3.10.12</div>
<div class="line"> </div>
<div class="line">module load intel_comp/2023.2.0 compiler mpi </div>
<div class="line">module load gnu_comp/13.1.0</div>
<div class="line"> </div>
<div class="line">./configure --enable-exahype --enable-blockstructured --enable-loadbalancing --enable-particles CC=icc CXX=icpx --with-multithreading=omp  CXXFLAGS=&quot;-std=c++20 -qopenmp -funroll-loops -Ofast -xHost&quot; LIBS=-ltbb</div>
</div><!-- fragment --><p>Previous modules/installations provided a oneAPI module. As this seems to be deprecated by Intel, one now has to load intel_comp and then the corresponding compiler and mpi.</p>
<p>The chip is from the Ice Lake-SP family, i.e. the generation released summer 2021. Without any further settings, OpenMP delivers a concurrency of around 11,170. This is due to two processors each featuring 28 cores with hyperthreading. I don't use hyperthreading usually, i.e. set</p>
<div class="fragment"><div class="line"><span class="keyword">export</span> OMP_NUM_THREADS=56</div>
<div class="line"><span class="keyword">export</span> OMP_PROC_BIND=<span class="keyword">true</span></div>
</div><!-- fragment --><p>I thought they have 2x40 cores, but my benchmarks give me an OpenMP concurrency of 11,170, which suggests it has 112 cores in total. Does that mean we have 2x28 and hyperthreading is enabled?</p>
<h1><a class="anchor" id="autotoc_md967"></a>
MAD08/MAD09 (Genoa)</h1>
<p><img src="https://www.dur.ac.uk/images/cosma/cosma_white.png" alt="" width="20%" class="inline"/></p>
<p>These two servers feature the Genoa chipset.</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> purge</div>
<div class="line"> </div>
<div class="line">module unload python</div>
<div class="line">module load python/3.10.12</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">module load intel_comp/2023.2.0 compiler mpi </div>
<div class="line">module load gnu_comp/13.1.0</div>
<div class="line"> </div>
<div class="line">./configure --enable-exahype --enable-blockstructured --enable-loadbalancing --enable-particles CC=icc CXX=icpx --with-multithreading=omp  CXXFLAGS=&quot;-std=c++20 -qopenmp -funroll-loops -Ofast -xHost&quot; LIBS=-ltbb</div>
</div><!-- fragment --><p>There are a few pitfalls with the AMD servers if you use the Intel toolchain. The Intel compiler does not recognise that the chip supports modern instruction sets. Notably, it is not aware of its AVX512 capabilities. Therefore, it produces machine code which does not use these features. You have to manually force it to produce the bytecode that you wanna have, by adding the compile flags</p>
<div class="fragment"><div class="line">-O3 -fomit-frame-pointer -fstrict-aliasing -ffast-math -funroll-loops -axCOMMON-AVX512 -march=x86-64-v4 -mavx512vbmi </div>
</div><!-- fragment --><p>Swift also requires you to pass</p>
<div class="fragment"><div class="line">-qopt-zmm-usage=high</div>
</div><!-- fragment --><p>to vectorisesome particular compute-heavy tasks (gravity).</p>
<h1><a class="anchor" id="autotoc_md968"></a>
Grace Hopper</h1>
<p>The Grace Hopper build configuration is similar to any other build:</p>
<div class="fragment"><div class="line">./configure CXX=nvc++ CC=nvc++ CXXFLAGS=<span class="stringliteral">&quot;-O4 --std=c++17 -mp=gpu -gpu=cc90,cuda12.3&quot;</span> LDFLAGS=<span class="stringliteral">&quot;-mp=gpu -gpu=cc90,cuda12.3&quot;</span> --with-multithreading=omp  --with-gpu=omp --enable-exahype --enable-blockstructured --enable-loadbalancing</div>
</div><!-- fragment --><p>It is important to use cc90 here plus a reasonably new CUDA version. Furthermore, most systems deliver the NC++ pipeline with a rather old GCC/STL version. It might be necessary to load a newer GCC. Depending on the SLURM configuration, people might have to request GPUs explicitly when they want a Grace Hopper node.</p>
<h1><a class="anchor" id="autotoc_md969"></a>
SuperMUC-NG Phase 2</h1>
<p><img src="https://www.lrz.de/bilder/logos/lrz-logos/lrz_logo_en.png" alt="" class="inline"/></p>
<p>On SuperMUC-NG Phase 2, we can basically rely on the standard Intel toolchain:</p>
<div class="fragment"><div class="line"><span class="keyword">module</span> load intel</div>
<div class="line">module load gcc</div>
<div class="line">./configure CC=icpx CXX=icpx CXXFLAGS=&quot;-Ofast -g -std=c++20 -mtune=native -march=native -fma -fomit-frame-pointer -fiopenmp -Wno-unknown-attributes --gcc-toolchain=/dss/lrzsys/sys/spack/release/24.1.0/opt/x86_64/gcc/13.2.0-gcc-itoa7pi/&quot; LDFLAGS=&quot;--gcc-toolchain=/dss/lrzsys/sys/spack/release/24.1.0/opt/x86_64/gcc/13.2.0-gcc-itoa7pi/ -fiopenmp -g&quot; --with-multithreading=omp --enable-exahype --enable-loadbalancing --enable-blockstructured --enable-particles</div>
</div><!-- fragment --><p>Some remark on this setup:</p>
<ul>
<li>The Intel module is at least 2024.</li>
<li>The default Intel module is built against an older GCC version. In this version, some filesystem routines and classes are still contained within std::experimental. Peano expects STL classes within std however. Therefore, we swap the STL manually. This might become obsolete with future compiler modules.</li>
<li>The toolchain also has to be known to the linker explicitly, so have to specify the path in the LDFLAGS, too.</li>
<li>Surprisingly, the code runs, once built also with system-level GCC versions. However, you have to load a recent GCC (13.0.0 here) manually before you launch any Peano application.</li>
</ul>
<h1><a class="anchor" id="autotoc_md970"></a>
AMD cloud machine</h1>
<p><img src="https://download.amd.com/OneTrust/202401.1.0a/consent/17a54836-920d-4fc2-a8f6-3f4c299371d1/0e234106-67d9-4371-9d2e-fba9f77b42f1/logos/522af4e3-8eb6-419a-ab34-33424f162acd/b5753b26-66ca-48b2-9cf8-f49f6f86d4fc/8ea1ec5d-9e72-477e-af81-45810eb32c32/AMD-Logo-700x394.png" alt="" size="50%" class="inline"/></p>
<p>This is a guideline for AMD Cloud machines that we use in hackathons, e.g. Login here works with standards ssh</p>
<div class="fragment"><div class="line">ssh username@aac1.amd.com -p myport</div>
</div><!-- fragment --><p>where you have to pick an active port (7000 or 7010). We only need one module for the core GPU tests:</p>
<div class="fragment"><div class="line">moduel load aomp/amdclang</div>
</div><!-- fragment --><p>(and older version is <code>module load amdclang/17.0-6.0.0</code>) and then use the following configuration:</p>
<div class="fragment"><div class="line">./configure CFLAGS=<span class="stringliteral">&quot;-D__AMDGPU__  -O3 -march=native -fopenmp -lstdc++fs --offload-arch=gfx90a&quot;</span> CC=<span class="stringliteral">&quot;amdclang&quot;</span> CXXFLAGS=<span class="stringliteral">&quot;-std=c++17 -w -O3 -march=native -fopenmp -lstdc++fs --offload-arch=gfx90a&quot;</span> CXX=<span class="stringliteral">&quot;amdclang++&quot;</span> LDFLAGS=<span class="stringliteral">&quot;-march=native -fopenmp -lstdc++fs --offload-arch=gfx90a&quot;</span> ./configure --with-multithreading=omp --with-gpu=omp --enable-exahype --enable-loadbalancing --enable-blockstructured</div>
</div><!-- fragment --><p>A good starting point for the GPU work is benchmarks/exahype2/ccz4/performance-testbed.</p>
<h1><a class="anchor" id="autotoc_md971"></a>
Example: Local WSL Ubuntu 22.04</h1>
<p>This configuration is meant to be a minimal build configuration when working with TBB locally. It is important to use an up-to-date c++ compiler such as icpx (e.g. g++-12 will not work with the c++-20 features used in Peano's tbb code).</p>
<p>First, the oneapi environment has to be set up:</p>
<div class="fragment"><div class="line">load <span class="keyword">module</span> intel</div>
</div><!-- fragment --><p>or</p>
<div class="fragment"><div class="line">source [path to oneapi installation]/setvars.sh</div>
</div><!-- fragment --><p>Configuration:</p>
<div class="fragment"><div class="line">./configure CC=icx CXX=icpx LIBS=<span class="stringliteral">&quot;-ltbb&quot;</span> CXXFLAGS=<span class="stringliteral">&quot;-std=c++20&quot;</span> --with-multithreading=<a class="code hl_namespace" href="../../df/d30/namespacetbb.html">tbb</a></div>
<div class="ttc" id="anamespacetbb_html"><div class="ttname"><a href="../../df/d30/namespacetbb.html">tbb</a></div><div class="ttdoc">I've written an API to IIT, but I'm not currently using.</div><div class="ttdef"><b>Definition</b> <a href="../../df/d8b/blocked__rangeNd_8h_source.html#l00032">blocked_rangeNd.h:32</a></div></div>
</div><!-- fragment --><p>With <a class="el" href="../../dd/d6c/namespaceexahype2.html" title="For the generic kernels that I use here most of the time.">exahype2</a>:</p>
<div class="fragment"><div class="line">./configure CC=icx CXX=icpx LIBS=<span class="stringliteral">&quot;-ltbb&quot;</span> CXXFLAGS=<span class="stringliteral">&quot;-std=c++20&quot;</span> --with-multithreading=<a class="code hl_namespace" href="../../df/d30/namespacetbb.html">tbb</a> --enable-exahype --enable-blockstructured --enable-loadbalancing</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md972"></a>
Leonardo</h1>
<div class="fragment"><div class="line"><span class="preprocessor">#!/bin/bash</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#SBATCH -A</span></div>
<div class="line"><span class="preprocessor">#SBATCH -p boost_usr_prod</span></div>
<div class="line"><span class="preprocessor">#SBATCH --job-name=MyJob</span></div>
<div class="line"><span class="preprocessor">#SBATCH --time=08:00:00</span></div>
<div class="line"><span class="preprocessor">#SBATCH -N 1</span></div>
<div class="line"><span class="preprocessor">#SBATCH --ntasks-per-node=4</span></div>
<div class="line"><span class="preprocessor">#SBATCH --cpus-per-task=4</span></div>
<div class="line"><span class="preprocessor">#SBATCH --gres=gpu:4</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">export</span> OMP_PLACES=cores</div>
<div class="line"><span class="keyword">export</span> OMP_PROC_BIND=close</div>
<div class="line"> </div>
<div class="line">ulimit -c unlimited</div>
<div class="line">ulimit -s unlimited</div>
<div class="line"> </div>
<div class="line"><span class="keyword">module</span> purge</div>
<div class="line">module load gcc</div>
<div class="line">module load cmake</div>
<div class="line">module load cuda</div>
<div class="line">module load openmpi/4.1.6--gcc--12.2.0</div>
<div class="line">module load netcdf-c/4.9.2--openmpi--4.1.6--gcc--12.2.0</div>
<div class="line">module load git-lfs/3.1.2</div>
<div class="line"> </div>
<div class="line">srun --cpu-bind=verbose,cores bash -c &#39;env CUDA_VISIBLE_DEVICES=$SLURM_PROCID ./Executable&#39;</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../index.html">Peano</a></li><li class="navelem"><a class="el" href="../../dd/d83/page_compiler_specific_settings_home.html">Vendor Software Stacks and System- and Compiler-specific Settings</a></li>
    <li class="footer">Generated on Tue Jul 1 2025 11:29:05 for Peano by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
